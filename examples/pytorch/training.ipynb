{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('merged_result.csv', delimiter=';')\n",
    "\n",
    "#filter\n",
    "df = df[df['Role'] == 'User']\n",
    "df = df[['Role', 'Message', 'Classification']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/base_events.py\", line 1986, in _run_once\n",
      "    handle._run()\n",
      "  File \"/usr/local/Cellar/python@3.12/3.12.5/Frameworks/Python.framework/Versions/3.12/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/4m/gdp1kgq565x8093n8p5c0nsw0000gn/T/ipykernel_42931/2678074461.py\", line 2, in <module>\n",
      "    from transformers import BertTokenizer\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/transformers/__init__.py\", line 26, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/transformers/utils/__init__.py\", line 34, in <module>\n",
      "    from .generic import (\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/transformers/utils/generic.py\", line 462, in <module>\n",
      "    import torch.utils._pytree as _torch_pytree\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Role                                            Message  \\\n",
      "0   User  que funcion hace el metodo stack push y stack pop   \n",
      "3   User              como saber la altura de un arbol dado   \n",
      "6   User  como saber la altura de un arbol dado unos val...   \n",
      "9   User                                   que es una deque   \n",
      "12  User                     que es un NullPointerException   \n",
      "\n",
      "          Classification  encoded_classification  \n",
      "0   Conceptual Questions                       2  \n",
      "3   Conceptual Questions                       2  \n",
      "6   Conceptual Questions                       2  \n",
      "9   Conceptual Questions                       2  \n",
      "12  Conceptual Questions                       2  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Inicializar o tokenizer do BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Codificar os rótulos em inteiros\n",
    "label_encoder = LabelEncoder()\n",
    "df['encoded_classification'] = label_encoder.fit_transform(df['Classification'])\n",
    "\n",
    "# Exibir as primeiras linhas para verificar\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do conjunto de treino: 219\n",
      "Tamanho do conjunto de teste: 55\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Dividir os dados em treino e teste\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Exibir o tamanho dos conjuntos\n",
    "print(f'Tamanho do conjunto de treino: {len(train_df)}')\n",
    "print(f'Tamanho do conjunto de teste: {len(test_df)}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        # Tokenização\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Defina alguns hiperparâmetros\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Criar os datasets\n",
    "train_dataset = TextClassificationDataset(\n",
    "    texts=train_df['Message'].to_numpy(),\n",
    "    labels=train_df['encoded_classification'].to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=MAX_LEN\n",
    ")\n",
    "\n",
    "test_dataset = TextClassificationDataset(\n",
    "    texts=test_df['Message'].to_numpy(),\n",
    "    labels=test_df['encoded_classification'].to_numpy(),\n",
    "    tokenizer=tokenizer,\n",
    "    max_len=MAX_LEN\n",
    ")\n",
    "\n",
    "# Criar os DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "\n",
    "class TextClassifier(torch.nn.Module):\n",
    "    def __init__(self, n_classes):\n",
    "        super(TextClassifier, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.drop = torch.nn.Dropout(p=0.3)\n",
    "        self.out = torch.nn.Linear(self.bert.config.hidden_size, n_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        pooled_output = outputs.pooler_output\n",
    "        output = self.drop(pooled_output)\n",
    "        return self.out(output)\n",
    "\n",
    "# Instanciar o modelo\n",
    "model = TextClassifier(n_classes=len(label_encoder.classes_))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 14/14 [01:55<00:00,  8.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss 0.5114, accuracy 0.8767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Movendo o modelo para a GPU se disponível\n",
    "model = model.to(device)\n",
    "\n",
    "# Definir otimizador e função de perda\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = CrossEntropyLoss().to(device)\n",
    "\n",
    "def train_epoch(model, data_loader, loss_fn, optimizer, device, n_examples):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for d in tqdm(data_loader):\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        labels = d[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, torch.tensor(losses).mean()\n",
    "\n",
    "# Treinamento por épocas\n",
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        model,\n",
    "        train_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        len(train_dataset)\n",
    "    )\n",
    "\n",
    "    print(f'Train loss {train_loss:.4f}, accuracy {train_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Teste de modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:07<00:00,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss 1.6510, accuracy 0.5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in tqdm(data_loader):\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            labels = d[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids,\n",
    "                attention_mask=attention_mask\n",
    "            )\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, torch.tensor(losses).mean()\n",
    "\n",
    "# Avaliar o modelo no conjunto de teste\n",
    "test_acc, test_loss = eval_model(\n",
    "    model,\n",
    "    test_loader,\n",
    "    loss_fn,\n",
    "    device,\n",
    "    len(test_dataset)\n",
    ")\n",
    "\n",
    "print(f'Test loss {test_loss:.4f}, accuracy {test_acc:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'interaction_model.bin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregar o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rodrigo/dev/uc3m/uc3m/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Carregar o modelo salvo\n",
    "model = TextClassifier(n_classes=len(label_encoder.classes_))\n",
    "model.load_state_dict(torch.load('interaction_model.bin'))\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Inicializar o tokenizer do BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_class(model, tokenizer, sentence, max_len=128):\n",
    "    # Tokenizar a frase\n",
    "    encoding = tokenizer.encode_plus(\n",
    "        sentence,\n",
    "        add_special_tokens=True,\n",
    "        max_length=max_len,\n",
    "        return_token_type_ids=False,\n",
    "        padding='max_length',\n",
    "        truncation=True,\n",
    "        return_attention_mask=True,\n",
    "        return_tensors='pt',\n",
    "    )\n",
    "\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    # Colocar o modelo em modo de avaliação e fazer a previsão\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        _, predicted_class = torch.max(outputs, dim=1)\n",
    "    \n",
    "    # Converter a previsão numérica de volta para o nome da classe original\n",
    "    predicted_class_name = label_encoder.inverse_transform([predicted_class.cpu().item()])[0]\n",
    "\n",
    "    return predicted_class_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification is: Conceptual Questions\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de frase\n",
    "frase = \"que tipos de datos no pueden usar los operadores logicos\"\n",
    "\n",
    "# Fazer a previsão\n",
    "classe_prevista = predict_class(model, tokenizer, frase)\n",
    "\n",
    "# Exibir o resultado\n",
    "print(f'Classification is: {classe_prevista}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
