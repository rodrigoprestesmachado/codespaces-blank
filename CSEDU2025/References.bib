@inproceedings{Ghimire24,
  author    = {Ghimire, Aashish
               and Edwards, John},
  editor    = {Olney, Andrew M.
               and Chounta, Irene-Angelica
               and Liu, Zitao
               and Santos, Olga C.
               and Bittencourt, Ig Ibert},
  title     = {Coding with AI: How Are Tools Like ChatGPT Being Used by Students in Foundational Programming Courses},
  booktitle = {Artificial Intelligence in Education},
  year      = {2024},
  publisher = {Springer Nature Switzerland},
  address   = {Cham},
  pages     = {259--267},
  abstract  = {Tools based on generative artificial intelligence (AI), such as ChatGPT, have quickly become commonplace in education, particularly in tasks like programming. We report on a study exploring how students use a tool similar to ChatGPT, powered by GPT-4, while working on Introductory Computer Programming (CS1) assignments, addressing a gap in empirical research on AI tools in education. Utilizing participants from two CS1 class sections, our research employed a custom GPT-4 tool for assignment assistance and the ShowYourWork plugin for keystroke logging. Prompts, AI replies, and keystrokes during assignment completion were analyzed to understand the state of students' programs when they prompt the AI, the types of prompts they create, and whether and how students incorporate the AI responses into their code. The results indicate distinct usage patterns of ChatGPT among students, including the finding that students ask the AI for help on debugging and conceptual questions more often than they ask the AI to write code snippets or complete solutions for them. We hypothesized that students ask conceptual questions near the beginning and debugging help near the end of program development do not find statistical evidence to support it. We find that large numbers of AI responses are immediately followed by the student copying and pasting the response into their code. The study also showed that tools like these are widely accepted and appreciated by students and deemed useful according to a student survey - suggesting that the integration of AI tools can enhance learning outcomes and positively impact student engagement and interest in programming assignments.},
  isbn      = {978-3-031-64299-9}
}

@article{Lo24,
  title    = {The influence of ChatGPT on student engagement: A systematic review and future research agenda},
  journal  = {Computers and Education},
  volume   = {219},
  pages    = {105100},
  year     = {2024},
  issn     = {0360-1315},
  doi      = {https://doi.org/10.1016/j.compedu.2024.105100},
  url      = {https://www.sciencedirect.com/science/article/pii/S0360131524001143},
  author   = {Chung Kwan Lo and Khe Foon Hew and Morris Siu-yung Jong},
  keywords = {ChatGPT, OpenAI, Student engagement, Systematic review, Artificial intelligence},
  abstract = {ChatGPT, a state-of-the-art artificial intelligence (AI) chatbot, has gained considerable attention as a transformative yet controversial tool for enhancing teaching and learning experiences. Several reviews and numerous articles have been written about harnessing ChatGPT in education since its release on November 30, 2022. Besides summarising its strengths, weaknesses, opportunities, and threats (SWOT) as identified in previous systematic reviews of ChatGPT research, this systematic review aims to develop a new understanding of its influence on student engagement by synthesising the existing related research using a three-dimensional framework comprising behavioural, emotional, and cognitive aspects. We searched relevant databases and included 72 empirical studies published within one year of ChatGPT's initial release. The findings reveal robust but narrowly focused evidence related to behavioural engagement (i.e., work with ChatGPT) and disengagement (i.e., academic dishonesty). The evidence related to the emotional aspect is mixed, with instances of both engagement (e.g., satisfaction and interest/fun) and disengagement (e.g., disappointment and worry/anxiety). There is broad but weak evidence regarding cognitive engagement (e.g., increased understanding and positive self-perception) and disengagement (e.g., reduced critical thinking and overreliance). Our review uncovers several under-explored indicators of student engagement, pointing to the need for further research. Specifically, future studies could focus on students' study habits and attendance (behavioural engagement), social interaction (emotional engagement), and self-regulation and critical thinking (cognitive engagement) in ChatGPT-supported learning environments.}
}

@article{Murillo23,
  title     = {Challenges and Opportunities of AI-Assisted Learning: A Systematic Literature Review on the Impact of ChatGPT Usage in Higher Education},
  author    = {Alfonso Renato Vargas-Murillo and Ilda Nadia Monica de la Asuncion Pari-Bedoya and Francisco de Jes\'us Guevara-Soto},
  journal   = {International Journal of Learning, Teaching and Educational Research},
  volume    = {22},
  number    = {7},
  pages     = {122-135},
  year      = {2023},
  publisher = {International Journal of Learning, Teaching and Educational Research},
  doi       = {10.26803/ijlter.22.7.7},
  url       = {http://ijlter.org/index.php/ijlter}
}

@article{cai23,
  title     = {Factors influencing learner attitudes towards ChatGPT-assisted language learning in higher education},
  author    = {Cai, Qianqian and Lin, Yupeng and Yu, Zhonggen},
  journal   = {International Journal of Human--Computer Interaction},
  pages     = {1--15},
  year      = {2023},
  publisher = {Taylor \& Francis}
}

@article{chan23,
  title     = {Students’ voices on generative AI: Perceptions, benefits, and challenges in higher education},
  author    = {Chan, Cecilia Ka Yuk and Hu, Wenjie},
  journal   = {International Journal of Educational Technology in Higher Education},
  volume    = {20},
  number    = {1},
  pages     = {43},
  year      = {2023},
  publisher = {Springer}
}

@article{zhang24,
  title     = {A systematic review of ChatGPT use in K-12 education},
  author    = {Zhang, Peng and Tur, Gemma},
  journal   = {European Journal of Education},
  volume    = {59},
  number    = {2},
  pages     = {e12599},
  year      = {2024},
  publisher = {Wiley Online Library}
}

@article{wu24,
  title     = {Promoting self-regulation progress and knowledge construction in blended learning via ChatGPT-based learning aid},
  author    = {Wu, Ting-Ting and Lee, Hsin-Yu and Li, Pin-Hui and Huang, Chia-Nan and Huang, Yueh-Min},
  journal   = {Journal of Educational Computing Research},
  volume    = {61},
  number    = {8},
  pages     = {3--31},
  year      = {2024},
  publisher = {SAGE Publications Sage CA: Los Angeles, CA}
}

@article{Puryear22,
  author     = {Puryear, Ben and Sprint, Gina},
  title      = {Github copilot in the classroom: learning to code with AI assistance},
  year       = {2022},
  issue_date = {November 2022},
  publisher  = {Consortium for Computing Sciences in Colleges},
  address    = {Evansville, IN, USA},
  volume     = {38},
  number     = {1},
  issn       = {1937-4771},
  abstract   = {Recent advances in deep machine learning have enabled artificial intelligence-driven development environments (AIDEs). AIDEs are programming tools that, given comments or starter code, can generate code solution suggestions. As the accuracy of these tools continues to increase, one particular AIDE from Github, Copilot, has been gaining significant attention for its performance and ease of use. The rise of Copilot suggests that code solution generation tools will soon be commonplace in both the industry and in computer science courses, with expert and novice programmers alike benefiting from using these tools. More specifically for novices, the effects of Copilot on the process of learning to code are mostly unknown. In this paper, we perform initial explorations into these effects. Using introductory computer science and data science courses, we evaluate Copilot-generated programming assignment solutions for correctness, style, skill level appropriateness, grade scores, and potential plagiarism. Our findings indicate Copilot generates mostly unique code that can solve introductory assignments with human-graded scores ranging from 68\% to 95\%. Based on these results, we provide recommendations for educators to help adapt their courses to incorporate new AIDE-based programming workflows.},
  journal    = {J. Comput. Sci. Coll.},
  month      = {nov},
  pages      = {37–47},
  numpages   = {11}
}

@inproceedings{Denny24,
  author    = {Denny, Paul and Leinonen, Juho and Prather, James and Luxton-Reilly, Andrew and Amarouche, Thezyrie and Becker, Brett A. and Reeves, Brent N.},
  title     = {Prompt Problems: A New Programming Exercise for the Generative AI Era},
  year      = {2024},
  isbn      = {9798400704239},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3626252.3630909},
  doi       = {10.1145/3626252.3630909},
  abstract  = {Large language models (LLMs) are revolutionizing the field of computing education with their powerful code-generating capabilities. Traditional pedagogical practices have focused on code writing tasks, but there is now a shift in importance towards reading, comprehending and evaluating LLM-generated code. Alongside this shift, an important new skill is emerging -- the ability to solve programming tasks by constructing good prompts for code-generating models. In this work we introduce a new type of programming exercise to hone this nascent skill: 'Prompt Problems'. Prompt Problems are designed to help students learn how to write effective prompts for AI code generators. A student solves a Prompt Problem by crafting a natural language prompt which, when provided as input to an LLM, outputs code that successfully solves a specified programming task. We also present a new web-based tool called Promptly which hosts a repository of Prompt Problems and supports the automated evaluation of prompt-generated code. We deploy Promptly in one CS1 and one CS2 course and describe our experiences, which include student perceptions of this new type of activity and their interactions with the tool. We find that students are enthusiastic about Prompt Problems, and appreciate how the problems engage their computational thinking skills and expose them to new programming constructs. We discuss ideas for the future development of new variations of Prompt Problems, and the need to carefully study their integration into classroom practice.},
  booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
  pages     = {296–302},
  numpages  = {7},
  keywords  = {ai code generation, artificial intelligence, generative ai, large language models, llms, prompt engineering, prompt problems},
  location  = {Portland, OR, USA},
  series    = {SIGCSE 2024}
}

@inproceedings{Prasad24,
  author    = {Prasad, Prajish and Sane, Aamod},
  title     = {A Self-Regulated Learning Framework using Generative AI and its Application in CS Educational Intervention Design},
  year      = {2024},
  isbn      = {9798400704239},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3626252.3630828},
  doi       = {10.1145/3626252.3630828},
  abstract  = {Self-regulation refers to the ability to plan, monitor, control and reflect on one's problem-solving process. Prior research has shown that self-regulated learning (SRL) strategies help improve novice performance in solving programming problems. However, with the advent of LLM tools like ChatGPT, novices can generate fairly accurate code by just providing the problem prompt, and hence may forego applying essential self-regulation strategies such as planning and reflection to solve the problem. In this position paper, we discuss challenges and opportunities that generative AI technologies pose for novices' self-regulation strategies in the context of programming problem solving. We believe that the key challenge facing educators is that such technologies may hamper novices' ability to regulate their programming problem solving process.On the other hand, these technologies also open up the possibility to design new interventions that promote better SRL strategies in learners. We draw on generic and domain-specific self-regulated learning theories as the basis of our work, and propose an SRL framework that incorporates use of generative AI tools in programming problem solving. We illustrate how the proposed framework guides exploration of the design space of interventions that integrate generative AI in CS education.},
  booktitle = {Proceedings of the 55th ACM Technical Symposium on Computer Science Education V. 1},
  pages     = {1070–1076},
  numpages  = {7},
  keywords  = {chatgpt, generative ai, llm, metacognition, pair programming, pair thinking, self-regulated learning, self-regulation, srl},
  location  = {Portland, OR, USA},
  series    = {SIGCSE 2024}
}

@inproceedings{Lauren23,
  author    = {P. Lauren and P. Watta},
  booktitle = {2023 IEEE Frontiers in Education Conference (FIE)},
  title     = {Work-in-Progress: Integrating Generative AI with Evidence-based Learning Strategies in Computer Science and Engineering Education},
  year      = {2023},
  volume    = {},
  issn      = {},
  pages     = {1-5},
  abstract  = {Generative AI assistants are AI-powered applications that can provide personalized responses to user queries or prompts. A variety of AI assistants have recently been released, and among the most popular is OpenAI&#x27;s ChatGPT. In this work-in-progress in innovative practice, we explore evidence-based learning strategies and the integration of Generative AI for computer science and engineering education. We expect this research will lead to innovative pedagogical approaches to enhance undergraduate computer science and engineering education. In particular, we describe how ChatGPT was used in two computing-based courses: a Junior-level course in database systems and a Senior-level class in mobile application development. We identify four evidence-based learning strategies: well-defined learning goals, authentic learning experiences, structured learning progression, and strategic assessment. We align these strategies with the two aforementioned courses and evaluate the usefulness of ChatGPT specifically in achieving the learning goals. Combining Generative AI with evidence-based learning has the potential to transform modern education into a more personalized learning experience.},
  keywords  = {computer science;transforms;chatbots;mobile communication;database systems;artificial intelligence;engineering education},
  doi       = {10.1109/FIE58773.2023.10342970},
  url       = {https://doi.ieeecomputersociety.org/10.1109/FIE58773.2023.10342970},
  publisher = {IEEE Computer Society},
  address   = {Los Alamitos, CA, USA},
  month     = {oct}
}


@article{Dickey24,
  author     = {Dickey, Ethan and Bejarano, Andres and Garg, Chirayu},
  title      = {AI-Lab: A Framework for Introducing Generative Artificial Intelligence Tools in Computer Programming Courses},
  year       = {2024},
  issue_date = {Jul 2024},
  publisher  = {Springer-Verlag},
  address    = {Berlin, Heidelberg},
  volume     = {5},
  number     = {6},
  url        = {https://doi.org/10.1007/s42979-024-03074-y},
  doi        = {10.1007/s42979-024-03074-y},
  journal    = {SN Comput. Sci.},
  month      = {jul},
  numpages   = {17},
  keywords   = {Generative AI (GenAI), Core skill development, Junior-Year Wall, Pedagogical framework, AI-Lab, ChatGPT}
}


@article{Baha24,
  author     = {Ait Baha, Tarek and El Hajji, Mohamed and Es-Saady, Youssef and Fadili, Hammou},
  title      = {The impact of educational chatbot on student learning experience},
  year       = {2023},
  issue_date = {Jun 2024},
  publisher  = {Kluwer Academic Publishers},
  address    = {USA},
  volume     = {29},
  number     = {8},
  issn       = {1360-2357},
  url        = {https://doi.org/10.1007/s10639-023-12166-w},
  doi        = {10.1007/s10639-023-12166-w},
  abstract   = {Artificial Intelligence (AI) technologies have increasingly become vital in our everyday lives. Education is one of the most visible domains in which these technologies are being used. Conversational Agents (CAs) are among the most prominent AI systems for assisting teaching and learning processes. Their integration into an e-learning system can provide replies suited to each learner's specific needs, allowing them to study at their own pace. In this paper, based on recent advancements in Natural Language Processing (NLP) and deep learning techniques, we present an experimental implementation of an educational chatbot intended to instruct secondary school learners Logo, an educational programming language. The related chatbot was implemented and evaluated in Moroccan public schools with the support of teachers from the Regional Center for Education and Training Professions of Souss Massa. The experiments included 109 students grouped into three separate classes. One is a control class group that uses a traditional approach, while the other two are experimental groups that employ digital content and the chatbot-based method. Preliminary findings indicate that employing chatbots can greatly enhance student learning experiences by allowing them to study at their own speed with less stress, saving them time, and keeping them motivated. Furthermore, integrating these AI systems into a smart classroom will not only create a supportive environment by encouraging good interactions with students, it will also allow learners to be more engaged and achieve better academic objectives.},
  journal    = {Education and Information Technologies},
  month      = {sep},
  pages      = {10153–10176},
  numpages   = {24},
  keywords   = {Educational chatbot, Learning experience, Virtual tutor, Conversational agent, E-learning, Chatbot's usability}
}

@article{catalan21,
  title   = {Conversational agent for supporting learners on a MOOC on programming with Java},
  author  = {Catal{\'a}n, Aguirre Cristina and Gonz{\'a}lez-Castro, Nuria and Delgado, Kloos Carlos and Alario-Hoyos, Carlos and Mu{\~n}oz-Merino, Pedro J},
  journal = {Computer Science and Information Systems},
  volume  = {18},
  number  = {4},
  pages   = {1271--1286},
  year    = {2021}
}

@article{neo22,
  title     = {THE MERLIN PROJECT: MALAYSIAN STUDENTS’ACCEPTANCE OF AN AI CHATBOT IN THEIR LEARNING PROCESS},
  author    = {Neo, Mai},
  journal   = {Turkish Online Journal of Distance Education},
  volume    = {23},
  number    = {3},
  pages     = {31--48},
  year      = {2022},
  publisher = {Anadolu University}
}

@article{Sun24,
  title   = {Benchmarking Large Language Models in Retrieval-Augmented
             Generation},
  volume  = {38},
  url     = {https://ojs.aaai.org/index.php/AAAI/article/view/29728},
  doi     = {10.1609/aaai.v38i16.29728},
  number  = {16},
  journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
  author  = {Chen, Jiawei and Lin, Hongyu and Han, Xianpei and Sun, Le},
  year    = {2024},
  month   = {Mar.},
  pages   = {17754-17762}
}


@article{Yilmaz23,
  title    = {Augmented intelligence in programming learning: Examining student
              views on the use of ChatGPT for programming learning},
  journal  = {Computers in Human Behavior: Artificial Humans},
  volume   = {1},
  number   = {2},
  pages    = {100005},
  year     = {2023},
  issn     = {2949-8821},
  doi      = {https://doi.org/10.1016/j.chbah.2023.100005},
  url      = {https://www.sciencedirect.com/science/article/pii/S2949882123000051},
  author   = {Ramazan Yilmaz and Fatma Gizem {Karaoglan Yilmaz}},
  keywords = {Generative artificial intelligence, ChatGPT, Programming,
              Programming learning, Student opinions}
}

@article{flavell79,
  title     = {Metacognition and cognitive monitoring: A new area of cognitive--developmental inquiry.},
  author    = {Flavell, John H},
  journal   = {American psychologist},
  volume    = {34},
  number    = {10},
  pages     = {906},
  year      = {1979},
  publisher = {American Psychological Association}
}


@article{Carvalho20,
  author   = {Carvalho, Paulo F.
              and Sana, Faria
              and Yan, Veronica X.},
  title    = {Self-regulated spacing in a massive open online course is related to better learning},
  journal  = {npj Science of Learning},
  year     = {2020},
  month    = {Mar},
  day      = {16},
  volume   = {5},
  number   = {1},
  pages    = {2},
  abstract = {In this study, we examined students' natural studying behaviors in massive, open, online course (MOOC) on introductory psychology. We found that, overall, distributing study across multiple sessions---increasing spacing---was related to increased performance on end-of-unit quizzes, even when comparing the same student across different time-points in the course. Moreover, we found important variation on who is more likely to engage in spaced study and benefit from it. Students with higher ability and students who were more likely to complete course activities were more likely to space their study. Spacing benefits, however, were largest for the lower-ability students and for those students who were less likely to complete activities. These results suggest that spaced study might work as a buffer, improving performance for low ability students and those who do not engage in active practices. This study highlights the positive impact of spacing in real-world learning situations, but more importantly, the role of self-regulated learning decisions in shaping the impact of spaced practice.},
  issn     = {2056-7936},
  doi      = {10.1038/s41539-020-0061-1},
  url      = {https://doi.org/10.1038/s41539-020-0061-1}
}

@article{Rivers21,
  author   = {Firth, Jonathan and Rivers, Ian and Boyle, James},
  title    = {A systematic review of interleaving as a concept learning strategy},
  journal  = {Review of Education},
  volume   = {9},
  number   = {2},
  pages    = {642-684},
  keywords = {interleaving, concept learning, memory, transfer, education},
  doi      = {https://doi.org/10.1002/rev3.3266},
  url      = {https://bera-journals.onlinelibrary.wiley.com/doi/abs/10.1002/rev3.3266},
  eprint   = {https://bera-journals.onlinelibrary.wiley.com/doi/pdf/10.1002/rev3.3266},
  abstract = {Abstract A systematic review was conducted into the effect of interleaving the order of examples of concepts in terms of both memory of items and transfer to new items. This concept has important implications for how and when teachers present examples in the classroom. A total of 26 studies met the inclusion criteria; a subset of 17 studies (with 32 constituent datasets) formed the basis of a meta-analysis, and the remainder were analysed within a narrative review. Memory (as tested by presenting studied items from a learned category) showed an interleaving benefit with effect sizes (Hedges’ g) of up to 0.65, and transfer (as tested by presenting novel items from a learned category) a benefit with effect sizes of up to 0.66. Interleaving was found to be of greatest use when differences between items are subtle, and the benefit extended to both art- and science-based items, with implication for practitioner decisions over how and when to apply the technique. It also extended to delayed tests. The review revealed that the literature is dominated by laboratory studies of university undergraduates, and the need for future school-based research using authentic classroom tasks is outlined.},
  year     = {2021}
}
