@inproceedings{10.1007/978-3-031-64299-9_20,
  author    = {Ghimire, Aashish
               and Edwards, John},
  editor    = {Olney, Andrew M.
               and Chounta, Irene-Angelica
               and Liu, Zitao
               and Santos, Olga C.
               and Bittencourt, Ig Ibert},
  title     = {Coding with AI: How Are Tools Like ChatGPT Being Used by Students in Foundational Programming Courses},
  booktitle = {Artificial Intelligence in Education},
  year      = {2024},
  publisher = {Springer Nature Switzerland},
  address   = {Cham},
  pages     = {259--267},
  abstract  = {Tools based on generative artificial intelligence (AI), such as ChatGPT, have quickly become commonplace in education, particularly in tasks like programming. We report on a study exploring how students use a tool similar to ChatGPT, powered by GPT-4, while working on Introductory Computer Programming (CS1) assignments, addressing a gap in empirical research on AI tools in education. Utilizing participants from two CS1 class sections, our research employed a custom GPT-4 tool for assignment assistance and the ShowYourWork plugin for keystroke logging. Prompts, AI replies, and keystrokes during assignment completion were analyzed to understand the state of students' programs when they prompt the AI, the types of prompts they create, and whether and how students incorporate the AI responses into their code. The results indicate distinct usage patterns of ChatGPT among students, including the finding that students ask the AI for help on debugging and conceptual questions more often than they ask the AI to write code snippets or complete solutions for them. We hypothesized that students ask conceptual questions near the beginning and debugging help near the end of program development do not find statistical evidence to support it. We find that large numbers of AI responses are immediately followed by the student copying and pasting the response into their code. The study also showed that tools like these are widely accepted and appreciated by students and deemed useful according to a student survey - suggesting that the integration of AI tools can enhance learning outcomes and positively impact student engagement and interest in programming assignments.},
  isbn      = {978-3-031-64299-9}
}

@inproceedings{10343037,
  author    = {Maher, Mary Lou and Tadimalla, Sri Yash and Dhamani, Dhruv},
  booktitle = {2023 IEEE Frontiers in Education Conference (FIE)},
  title     = {An Exploratory Study on the Impact of AI tools on the Student Experience in Programming Courses: an Intersectional Analysis Approach},
  year      = {2023},
  volume    = {},
  number    = {},
  pages     = {1-5},
  keywords  = {Java;Schedules;Data collection;Chatbots;Behavioral sciences;Artificial intelligence;Task analysis;ChatGPT;CS education;Student Experience;Intersectionality},
  doi       = {10.1109/FIE58773.2023.10343037}
}

@article{LO2024105100,
  title    = {The influence of ChatGPT on student engagement: A systematic review and future research agenda},
  journal  = {Computers and Education},
  volume   = {219},
  pages    = {105100},
  year     = {2024},
  issn     = {0360-1315},
  doi      = {https://doi.org/10.1016/j.compedu.2024.105100},
  url      = {https://www.sciencedirect.com/science/article/pii/S0360131524001143},
  author   = {Chung Kwan Lo and Khe Foon Hew and Morris Siu-yung Jong},
  keywords = {ChatGPT, OpenAI, Student engagement, Systematic review, Artificial intelligence},
  abstract = {ChatGPT, a state-of-the-art artificial intelligence (AI) chatbot, has gained considerable attention as a transformative yet controversial tool for enhancing teaching and learning experiences. Several reviews and numerous articles have been written about harnessing ChatGPT in education since its release on November 30, 2022. Besides summarising its strengths, weaknesses, opportunities, and threats (SWOT) as identified in previous systematic reviews of ChatGPT research, this systematic review aims to develop a new understanding of its influence on student engagement by synthesising the existing related research using a three-dimensional framework comprising behavioural, emotional, and cognitive aspects. We searched relevant databases and included 72 empirical studies published within one year of ChatGPT's initial release. The findings reveal robust but narrowly focused evidence related to behavioural engagement (i.e., work with ChatGPT) and disengagement (i.e., academic dishonesty). The evidence related to the emotional aspect is mixed, with instances of both engagement (e.g., satisfaction and interest/fun) and disengagement (e.g., disappointment and worry/anxiety). There is broad but weak evidence regarding cognitive engagement (e.g., increased understanding and positive self-perception) and disengagement (e.g., reduced critical thinking and overreliance). Our review uncovers several under-explored indicators of student engagement, pointing to the need for further research. Specifically, future studies could focus on students' study habits and attendance (behavioural engagement), social interaction (emotional engagement), and self-regulation and critical thinking (cognitive engagement) in ChatGPT-supported learning environments.}
}